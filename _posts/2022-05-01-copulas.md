---
layout: post
title: "Copulas in Probability Theory"
category: "Money and Finance"
---

The term "Copula" was coined by [Abe Sklar](https://en.wikipedia.org/wiki/Abe_Sklar) in his 1959 article, which was written in French[^1]. Copulas have been widely used, though not always applied properly, in financial and econometric modeling, especially in pricing securities that depend on many underlying securities. Formally put, for an $n$-variate function $F$, the copula associated with $F$ is a distribution function $C: [0, 1]^{n} \rightarrow [0, 1]$ that satisfies

$$F(y_{1}, \dots , y_{n}) = C(F_{1}(y_{1}), \dots , F_{n}(y_{n}) ; \theta),$$

where $\theta$ is a parameter of the copula called the **dependence parameter**{: style="color: red"}, which means dependence between the marginals. This is a frequent starting point of empirical applications.<br />

<!-- excerpt-end -->

## Table of Contents
{:.no_toc}
* TOC 
{:toc}
<br />

## Basic Concepts

Properties of copulas are analogous to properties of joint distributions. The **joint distribution**{: style="color: red"} of a set of random variables $(Y_{1}, \dots , Y_{m})$ is defined as

$$F(y_{1}, \dots , y_{m}) = \mathbb{P}\{Y_{i} \leq y_{i}; i = 1, \dots , m\},$$

and the **survival function**{: style="color: red"} corresponding to $F(y_{1}, \dots , y_{m})$ is given by $$\overline{F}(y_{1}, \dots , y_{m}) = \mathbb{P}\{Y_{i} > y_{i}; i = 1, \dots , m\}.$$

**Definition 1.** An $n$-dimensional copula (briefly, an *n-copula*) is a function $C$ from the unit $n$-cube $[0, 1]^{n}$ to the unit interval $[0, 1]$ which satisfies the following conditions:

1. $C(1, \dots , 1, a_{m}, 1, \dots , 1) = a_{m}$ for each $m \leq n$ and all $a_{m} \in [0, 1]$.

2. $C(a_{1}, \dots , a_{n}) = 0$ if $a_{m} = 0$ for any $m \leq n$.

3. $C$ is $n$-increasing in the sense that the $C$-volume of any $n$-dimensional interval is non-negative. In particular, if $C$ is a $2$-dimensional copula, then

4. $C(a_{2}, b_{2}) - C(a_{1}, b_{2}) - C(a_{2}, b_{1}) + C(a_{1}, b_{1}) \geq 0$, whenever $a_{1} \leq a_{2}$, $b_{1} \leq b_{2}$.

**Property 1** says that if the realizations of $n - 1$ variables are known each with marginal probability one, then the joint probability of the $n$ outcomes is the same as the probability of the remaining uncertain outcome. **Property 2** (sometimes referred to as the **grounded** property of a copula) says that the joint probability of all outcomes is zero if the marginal probability of any outcome is zero. An $n$-copula may be viewed, or equivalently defined as an $n$-dimensional cumulative probability distribution function whose support is contained in $[0, 1]^{n}$ and whose one-dimensional margins are uniform on $[0, 1]$[^2]. In other words, an $n$-copula is an $n$-dimensional distribution function with all $n$ univariate margins being $U(0, 1)$[^3].

Sklar's basic result is now the following:

**Theorem 1.** If $H$ is an $n$-dimensional probability distribution function with one-dimensional margins $F_{1}, \dots , F_{n}$, then there exists an $n$-dimensional copula $C$ such that, for all $x_{1}, \dots , x_{n} \in \mathbb{R}$, $$H(x_{1}, \dots , x_{n}) = C(F_{1}(x_{1}), \dots , F_{n}(x_{n})).$$

Moreover, letting $u_{i} = F_{i}(x_{i}), i = 1, \dots , n$, yields

$$C(u_{1}, \dots , u_{n}) = H(F^{-1}(u_{1}), \dots , F_{n}^{-1}(u_{n})),$$

where, for any one-dimensional distribution function $F$,

$$F^{-1}(t) = \sup \{ x \mid F(x) < t \},$$

or equivalently,

$$F^{-1}(t) = \inf \{ x \mid F(x) \geq t \}$$

(quasi-inverse, or the "quantile transform"). In practice, econometricians often know a great deal about marginal distributions of individual variables but little about their joint behavior. These results show that much of the study of joint distribution functions can be reduced to the study of copulas!

To prove Sklar's theorem, we shall introduce the notion of "**distributional transform**{: style="color: red"}":

**Definition 2.** Let $Y$ be a real random variable with distribution function $F$ and let $V$ be a random variable independent of $Y$, such that $V \sim U(0, 1)$. The modified distribution function $F(x, \lambda)$ is defined by

$$F(x, \lambda) := \mathbb{P}\{X < x\} + \lambda \mathbb{P}(Y = x).$$

We call $U := F(Y, V)$ the (generalized) distributional transform of $Y$.

**Proof of Theorem 1.**  Let $X = (X_{1}, \dots , X_{n})$ be a random vector on a probability space with distribution function $F$ and let $V \sim U(0, 1)$ be independent of $X$. Considering the distributional transforms $U_{i} := F_{i}(X_{i}, V), 1 \leq i \leq n$, we have $U_{i} \overset{d}{=} U(0, 1)$ and $X_{i} = F_{i}^{-1}(U_{i})$ a.s., $1 \leq i \leq n$. Thus, defining $C$ to be the distribution function of $U = (U_{1}, \dots , U_{n})$ we obtain

$$
\begin{align}
F(x) &= \mathbb{P}\{X \leq x\} \\
     &= \mathbb{P}\{F_{i}^{-1}(U_{i}) \leq x_{i}, 1 \leq i \leq n\} \\
     &= \mathbb{P}\{U_{i} \leq F_{i}(x_{i}), 1 \leq i \leq n\} \\
     &= C(F_{1}(x_{1}), \dots , F_{n}(x_{n})),    
\end{align}
$$

i.e. $C$ is a copula of $F$.

### Some common bivariate copulas

-    **Product copula**{: style="color: red"}<br />
     $C(u_{1}, u_{2}) = u_{1}u_{2}$, where $u_{1}$ and $u_{2}$ take values in the unit interval of the real line.
-    **Farlie-Gumbel-Morgenstern (FGM) copula**{: style="color: red"}<br />
     $C(u_{1}, u_{2} ; \theta) = u_{1}u_{2}[1 + \theta(1 - u_{1})(1 - u_{2})]$[^4].
-    **Gaussian (normal) copula**{: style="color: red"}<br />
     $C(u_{1}, u_{2} ; \theta) = \int_{-\infty}^{\Phi^{-1}(u_{1})} \int_{-\infty}^{\Phi^{-1}(u_{2})} \frac{1}{2\pi(1 - \theta^{2})^{1/2}} \cdot \frac{-(s^{2} - 2\theta s t + t^{2})}{2(1 - \theta^{2})}\,\mathrm{d}s\,\mathrm{d}t$, where $\Phi$ is the cdf of the standard normal distribution. In [Lee (1983)](https://www.jstor.org/stable/1912003?seq=1)[^5], Gaussian copula was proposed to tackle the censored regression model:
  
     $$
     \begin{align} 
          y_{1} &= x \beta + \sigma u, \quad \sigma > 0,\\
          y^{*} &= z \gamma - \epsilon,
     \end{align}
     $$

     in which $u$ and $\epsilon$ conditional on $x$ and $z$ have absolutely continuous distribution functions, but the joint bivariate distribution of $u$ and $\epsilon$ is not specified.
-    **Student's t-copula**{: style="color: red"}<br />
     ${\scriptstyle C^{t}(u_{1}, u_{2} ; \theta_{1}, \theta_{2}) = \int_{-\infty}^{t_{\theta_{1}}^{-1}(u_{1})} \int_{-\infty}^{t_{\theta_{2}}^{-1}(u_{2})} \frac{1}{2\pi(1 - \theta_{2}^{2})^{1/2}} \cdot \biggl( 1 + \frac{s^{2} - 2\theta_{2} s t + t^{2}}{\nu(1 - \theta_{2}^{2})} \biggr)^{-(\theta_{1} + 2)/2}\,\mathrm{d}s\,\mathrm{d}t}$,<br />
     where $t_{\theta_{1}}^{-1}(u_{1})$ denotes the inverse of the cdf of the standard univariate $t$-distribution with $\theta_{1}$ degrees of freedom ($\theta_{1}$ controls the heaviness of the tails), and $\nu$ / $\rho$ denotes degrees of freedom / correlation of the bivariate $t$-distribution.
-    **Clayton copula**{: style="color: red"}<br />
     $C(u_{1}, u_{2} ; \theta) = (u_{1}^{-\theta} + u_{2}^{-\theta} - 1)^{-1/\theta}$ with the dependence parameter $\theta$ restricted on the region $(0, \infty)$.
-    **Frank copula**{: style="color: red"}<br />
     $C(u_{1}, u_{2} ; \theta) = -\theta^{-1} \log\biggl( 1 + \frac{(e^{-\theta u_{1}} - 1)(e^{-\theta u_{2}} - 1)}{e^{-\theta} - 1}\biggr)$ with the dependence parameter assuming any real value.
-    **Gumbel copula**{: style="color: red"}<br />
     $$C(u_{1}, u_{2} ; \theta) = \exp\biggl(-(u'_{1}^{\theta} + u'_{2}^{\theta})^{1/\theta}\biggr),$$
     where
     $$u'_{j} = -\log u_{j}, \theta \in [1, \infty)$$.

### The Frechet bounds for a copula

Given an arbitrary $n$-variate joint cdf $F(y_{1}, \dots , y_{n})$ with univariate marginal cdfs $F_{1}, \dots , F_{n}$, the joint cdf is bounded below and above by the Frechet-Hoeffding lower and upper bounds, $F_{L}$ and $F_{U}$, defined as

$$
\begin{align}
F_{L}(y_{1}, \dots , y_{n}) &= \max \{ \sum\limits_{j = 1}^{n} F_{j} - n + 1, 0 \}, \\
F_{U}(y_{1}, \dots , y_{n}) &= \min \{ F_{1}, \dots , F_{n} \},
\end{align}
$$

which satisfy

$$\max \{ \sum\limits_{j = 1}^{n} F_{j} - n + 1, 0 \} \leq F(y_{1}, \dots , y_{n}) \leq \min \{ F_{1}, \dots , F_{n} \}.$$

The upper bound is always a cdf while the lower bound is a cdf for $n = 2$.

This definition also applies to copulas:

$$\max \{ \sum\limits_{j = 1}^{n} F_{j} - n + 1, 0 \} \leq C(y_{1}, \dots , y_{n}) \leq \min \{ F_{1}, \dots , F_{n} \}$$

Knowledge of Frechet-Hoeffding bounds is important in selecting an appropriate copula. The desirable feature of a copula is that it should cover the sample space between the lower and the upper bounds and that as $\theta$ approaches the lower (upper) bound of its permissible range, the copula approaches the Frechet-Hoeffding lower (upper) bound.

## Construction of a Copula


## References

[^1]: Abe Sklar, Random Variables, Distribution Functions, and Copulas, *Kybernetika*, Vol. 9, No. 6 (1973), pp. 449-460.

[^2]: Berthold Schweizer, Thirty Years of Copulas, In: G. Dall' Aglio, S. Kotz, and G. Salinetti (eds.): *Advances in Probability Distributions with Given Marginals: Beyond the Copulas.* The Netherlands: Kluwer Academic Publishers.

[^3]: Pravin K. Trivedi and David M. Zimmer, *Copula Modeling: An Introduction for Practitioners* Foundations and Trends in Econometrics, Vol. 1, No. 1 (2005) pp. 1-111.

[^4]: James E. Prieger, A Flexible Parametric Selection Model for Non-Normal Data with Application to Health Care Usage, *Journal of Applied Econometrics*, Vol. 17, No. 4 (2002), pp. 367-392. In this article, FGM copula is chosen for sample selection in that "the marginal distributions in he FGM system may be of any form, as long as their cdfs are absolutely continuous."

[^5]: Lung-Fei Lee, Generalized Econometric Models with Selectivity, *Econometrica*, Vol. 51, No. 2 (1983), pp. 507-512.